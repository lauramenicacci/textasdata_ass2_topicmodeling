---
title: "TaD_Assignment_2"
author: "Laura Menicacci"
date: '2022-11-13'
output: html_document
---

```{r}
# setwd('C:\\Users\\laura\\OneDrive\\Documenti\\LAURA\\HERTIE 22-23\\Text_as_Data_class')

getwd()
```


```{r setup, include=FALSE}

library(tidyverse)

library(quanteda)
library(manifestoR)
# library(quanteda.textmodels) 
# library(quanteda.textplots)
library(ggplot2)
library(readtext)
library(lexicon)
library(reticulate)
library(lubridate)
library(corrplot)
```


## Download data
```{r}
mp_setapikey(key.file = "C:\\Users\\laura\\OneDrive\\Documenti\\LAURA\\HERTIE 21-22\\Introduction to DS\\manifesto_apikey.txt")

```

## Filter dataset by italy & create corpus
 - we filter from 1990 to reduce scope and also because it can be considered as a turning point for climate change awareness 
 (ex. 1992 rio)
 
```{r}
us <- mp_availability(countryname  == "United States")

e <- mp_corpus(us)

```

```{r}
e_corpus <- e %>%
  as.data.frame(with.meta = TRUE) %>%
  corpus(docid_field = "manifesto_id", unique_docnames = FALSE) %>% 
  corpus()

e_corpus

e_corpus %>%
  docvars()

e_corpus$party
```


## What years, countries and parties are included in the dataset? How many texts do you have for each of these

```{r}

# manifestos per year

us %>% 
  group_by(date) %>% 
  count %>% 
  ggplot(aes(x = date, y = n))+
  geom_line() + geom_point() +
  scale_x_continuous() +
  theme_bw()
  
# parties per year 

us %>% 
  group_by(date) %>% 
  count %>% 
  ggplot(aes(x = it$party, y = date))+
  geom_line() + geom_point() +
  scale_x_continuous(labels = c(seq(1946, 2018, 12)), breaks = seq(194606, 201803, 12)) +   theme_bw()

# texts



# plot n of text per parties, per countries and per years 
```


# Explorative analysis: explore all codes taken into consideration

## Prepare your data for topic modelling by creating a document feature matrix. Describe the choices you make here, and comment on how these might affect your final result.


- spiega xk lemmatization and not stemming 
- stemming because we have a lot of documents? process less data? 

```{r}
tokenized_manifesto <- e_corpus %>%
  tokens() %>% 
  tokens(remove_punct = TRUE, remove_numbers = TRUE) %>%
  tokens_tolower() %>%
  tokens_remove(stopwords("english")) %>% 
  tokens_remove(c("will")) %>% 
  tokens_replace(pattern = lexicon::hash_lemmas$token, replacement = lexicon::hash_lemmas$lemma)
```

## Dfm ready to be used

```{r}
manifesto_dfm <- tokenized_manifesto %>% 
  dfm() %>% 
  dfm_subset(!(cmp_code %in% c("H", "", "0", "000", NA))) %>% 
  dfm_subset(cmp_code %in% c('607.3', '602.2', '601.2', '503', '201.2', '606.2', '501'))
```

## some exploratory plotting

```{r}

manif_plot_cmp <- manifesto_dfm %>% dfm_group(cmp_code)

library(quanteda.textstats)
feature_frequencies_cat <- manif_plot_cmp %>% textstat_frequency(n = 5, group = cmp_code)

feature_frequencies_cat %>%
  mutate(group = case_when(
    group == "607.3" ~ "Indigenous rights: Positive", 
    group == "608.3" ~ "Indigenous rights: Negative", 
    group == "602.2" ~ "Immigration: Positive", 
    group == "601.2" ~ "Immigration: Negative", 
    group == "503" ~ "Equality: Positive", 
    group == "201.2" ~ "Human Rights", 
    group == "606.2" ~ "Bottom-Up Activism", 
    group == "501" ~ "Environmental Protection")) %>%
  ggplot(aes(x = reorder(feature, frequency), y = frequency, fill = group)) +
  geom_col(show.legend = FALSE) +
  labs(x = NULL, y = "share of words per cmp category") +
  facet_wrap(~group, ncol = 2, scales = "free") +
  coord_flip() +
  theme_bw()

ggsave('plots\top_words_cmp.png', width = 12, height = 8)
```



comment: theres no indigenous rights negative!

```{r}
manif_plot_party <- manifesto_dfm %>% dfm_group(party)

feature_frequencies_cat <- manif_plot_party %>% textstat_frequency(n = 15, group = party)

feature_frequencies_cat %>%
  mutate(group = case_when(
    group == "61320" ~ "Democratic",
    group == "61620" ~ "Republican"
  )) %>%
  ggplot(aes(x = reorder(feature, frequency), y = frequency, fill = group)) +
  geom_col(show.legend = FALSE) +
  labs(x = NULL, y = "share of words per party") +
  facet_wrap(~group, ncol = 2, scales = "free") +
  coord_flip() +
  theme_bw() 

ggsave('plots\top_words_party.png', width = 12, height = 8)

```


# maybe another graph with top words per manifesto id 

 - n of sentences per code + 
 - years of these manyfestos 

```{r}

```


# Describe a research question you want to explore with topic modelling. Comment on how answerable this is with the methods and data at your disposal.

## Research question: 

1. Looking out for climate justice in the political manifestos in the United States. 

can environmental protection and elements of social justice / social welfare be considered similar? 

One can easily assume that these are two separate topics, but what's their political role when parties write their manifestos? could they have some political connections or correlations? 

In the context of the united states, this are themes particularly covered by the democratic party. But how do they talk about it? In which way they use such topics? Can they have a similar political role? If yes, can this be expressed in the way they talk about it? 

Topic modeling will help us to understand if these topics are classified as extremely distinct or they have some overlaps. 

Description: only after 90s --> bush was the first to talk about it

In this assignment i will inspect possible connections with the topics of social welfare and environmental protection, and see if they have anything in common 

TO DO: 
select all the english speaking countries - select all the codes that could involve climate justice 
 
 * 607.3 Indigenous rights: Positive 
 * 608.3 Indigenous rights: Negative 
 * 602.2 Immigration: Positive
 * 601.2 Immigration: Negative
 * 503 Equality: Positive
 * 201.2 Human Rights 
 * 606.2 Bottom-Up Activism 
 * 501 Environmental protection 



check number of documents: 10 manifestos selected --> manifesto_dfm$id %>% unique() to see unique names of manifestos 

comment about party imbalance 

# Create a topic model using your data. Explain to a non-specialist what the topic model does. Comment on the choices you make here in terms of hyperparameter selection and model choice. How might these affect your results and the ability to answer your research question?

### Describe the topic model. What topics does it contain? How are these distributed across the data?


## Use your topic model to answer your research question by showing plots or statistical results. Discuss the implications of what you find, and any limitations inherent in your approach. Discuss how the work could be improved upon in future research.

### Topic modeling: inspecting topic similarity with lda function in topicmodels package

```{r}
library(topicmodels)

lda_tidy <- LDA(manifesto_dfm, 9)

library(reshape2)
library(tidytext)

topic_words <- tidy(lda_tidy, matrix="beta") %>%
  group_by(topic) %>%
  slice_max(beta, n = 5) %>% 
  ungroup() %>%
  arrange(topic, -beta)
  
topic_words %>%   
  mutate(topic = paste0("Topic ", topic),
           term = reorder_within(term, beta, topic)) %>%
  ggplot(aes(term, beta, fill = as.factor(topic))) +
  geom_col(alpha = 0.8, show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free_y") +
  coord_flip() +
  scale_x_reordered() +
  labs(x = NULL, y = expression(beta),
         title = "Highest word probabilities for each topic",
         subtitle = "Different words are associated with different topics")

```
Visualize Lda & topic overlap by phi value


```{r}
# lda visualization: https://knowledger.rbind.io/post/topic-modeling-using-r/
library(LDAvis)

topicmodels2LDAvis <- function(x, ...){
  post <- topicmodels::posterior(x)
  if (ncol(post[["topics"]]) < 3) stop("The model must contain > 2 topics")
  mat <- x@wordassignments
  json <- LDAvis::createJSON(
    phi = post[["terms"]],
    theta = post[["topics"]],
    vocab = colnames(post[["terms"]]),
    doc.length = slam::row_sums(mat, na.rm = TRUE),
    term.frequency = slam::col_sums(mat, na.rm = TRUE)
)
return(json)
}

json <- topicmodels2LDAvis(lda_tidy)
serVis(json)

```
Comment: topic 2 and 8 are overlapping: one of them talks about climate change (at least as it seems). What does it mean? 



Compare the found topics and see if they are correlated! 

```{r}
head(topics(lda_tidy), 10) # these are the 10 documents with the highest probability of belonging to this topic, let's inspect the first one 

e_corpus[['61320_199211.19']]
```


```{r}
# Creates a dataframe to store the document id and the most likely topic

# doc_x_topic <- as.data.frame(topicmodels::posterior(lda_tidy)$topics)
head(doc_x_topic) # probabilities of the first 5 documents to belong to that topic 

topics <- (topics(lda_tidy))
lda_topics <- as.data.frame(topics)

lda_topics <- dplyr::transmute(lda_topics, ManifestoId = rownames(lda_topics), Topic = topics)

head(lda_topics)

lda_topics %>% 
  ggplot(aes(x = Topic)) + geom_bar(fill = 'lightblue') + scale_x_discrete(labels = labels) + ylab('Distribution of documents per topic') + xlab('Topics') + theme_bw()
```


```{r}

prob_x_topic <- as.data.frame(topicmodels::posterior(lda_tidy)$topics)

library(corrplot)
c <- cor(prob_x_topic)
corrplot(c, method = "circle")

```
LDA is a probabilistic model, which means that if you re-train it with the same hyperparameters, you will get different results each time. 

If we retrain the model multiple times and the environmental-related topic and the other one stay similar: we can say that there are some topic similarities according to LDA. 

A good practice is to run the model with the same number of topics multiple times and then average the topic coherence.

I will use a different package this time (textmineR) to perform multiple ldas and evaluate coherence and performance 

### coherence and prevalence 

First subset the dfm by the code of interest, then perform lda with textminingR 

```{r}
library(textmineR)

e_corpus_lda1 <- e_corpus %>% 
  corpus_subset(!(cmp_code %in% c("H", "", "0", "000", NA))) %>% 
  corpus_subset(cmp_code %in% c('501', '503')) # %>% 
  corpus_group(id)

dtm1 <- CreateDtm(doc_vec = e_corpus_lda1,
                   doc_names = e_corpus_lda1$id,
                   ngram_window = c(1,2),
                   stopword_vec = stopwords("en"),
                   verbose = F)

lda1 <- FitLdaModel(dtm = dtm1,
                         k = 10, # number of topic
                         iterations = 50,
                         burnin = 5,
                         alpha = 0.1,
                         beta = 0.05,
                         optimize_alpha = T,
                         calc_likelihood = T,
                         calc_coherence = T,
                         calc_r2 = T)

```

Inspect results and plot coherence and prevalence

explain what is coherence
explain what is prevalence

What is coherence and coherence score? Coherence gives the probabilistic coherence of each topic. Coherence score is a score that calculates if the words in the same topic make sense when they are put together. This gives us the quality of the topics being produced. The higher the score for the specific number of k, it means for each topic, there will be more related words together and the topic will make more sense

We also want to look at prevalence value. Prevalence tells us the most frequent topics in the corpus. Prevalence is the probability of topics distribution in the whole documents.

```{r}
top_terms <- GetTopTerms(phi = lda1$phi, M = 15) #distribution of 
lda1$top_terms

lda1$coherence

lda1$prevalence <- colSums(lda1$theta)/sum(lda1$theta)*100
lda1$prevalence

lda1$summary <- data.frame(topic = rownames(lda1$phi),
                                coherence = round(lda1$coherence,3),
                                prevalence = round(lda1$prevalence,3),
                                top_terms = apply(lda1$top_terms,2,function(x){paste(x,collapse = ", ")}))

modsum1 <- lda1$summary %>%
  `rownames<-`(NULL)

modsum1 %>% pivot_longer(cols = c(coherence,prevalence)) %>%
  ggplot(aes(x = factor(topic,levels = unique(topic)), y = value, group = 1)) +
  geom_point() + geom_line() +
  facet_wrap(~name,scales = "free_y",nrow = 2) +
  theme_minimal() +
  labs(title = "Best topics by coherence and prevalence score",
       subtitle = "Topics including 501 and 503 cmp codes",
       x = "Topics", y = "Value")
```


```{r}

k_list <- seq(1, 8, by = 1)
model_dir <- paste0("models_", digest::digest(dtm1, algo = "sha1"))
if (!dir.exists(model_dir)) dir.create(model_dir)
model_list <- TmParallelApply(X = k_list, FUN = function(k){
  filename = file.path(model_dir, paste0(k, "_topics.rda"))
  
  if (!file.exists(filename)) {
    m <- FitLdaModel(dtm = dtm1, k = k, iterations = 50)
    m$k <- k
    m$coherence <- CalcProbCoherence(phi = m$phi, dtm = dtm1, M = 5)
    save(m, file = filename)
  } else {
    load(filename)
  }
  
  m
}, export=c("dtm1", "model_dir")) # export only needed for Windows machines
#model tuning
#choosing the best model
coherence_mat <- data.frame(k = sapply(model_list, function(x) nrow(x$phi)), 
                            coherence = sapply(model_list, function(x) mean(x$coherence)), 
                            stringsAsFactors = FALSE)
ggplot(coherence_mat, aes(x = reorder(k, coherence), y = coherence)) +
  geom_bar(stat = "identity", fill = 'lightblue') +
  ggtitle("Best Topic by Coherence Score") + theme_minimal() + ylab("Coherence") +xlab('Topic')
```

################################################################################ 



Coherence matrix across different topic models 
```{r}
model_list <- list(modsum1, modsum2)

coherence_mat <- data.frame(k = sapply(model_list, function(x) nrow(x$phi)), 
                            coherence = sapply(model_list, function(x) mean(x$coherence)), 
                            stringsAsFactors = FALSE)

ggplot(coherence_mat, aes(x = k, y = coherence)) +
  geom_point() +
  geom_line(group = 1)+
  ggtitle("Best Topic by Coherence Score") + theme_minimal() +
  scale_x_continuous(breaks = seq(1,20,1)) + ylab("Coherence")
```



```{r}
lda1$linguistic <- CalcHellingerDist(lda1$phi)
lda1$hclust <- hclust(as.dist(lda1$linguistic),"ward.D")
lda1$hclust$labels <- paste(lda1$hclust$labels, lda1$labels[,1])
plot(lda1$hclust)
```

